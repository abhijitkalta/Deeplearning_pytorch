{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "20029a25-606e-427e-9fde-4c149feb6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "499952c2-ef12-40c2-9daf-10da16ae5d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12bbe09b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c11f322f-d1fc-4697-96c0-814bb0d343d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset imdb (/Users/abhijit/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "WARNING:datasets.builder:Found cached dataset imdb (/Users/abhijit/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "test_dataset = load_dataset(\"imdb\", split=\"test\")\n",
    "\n",
    "trainset = Subset(train_dataset, range(0, 20000))\n",
    "validset = Subset(train_dataset, range(20000, 25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee0a5dd6-e73e-43fa-84dc-13f5fe5b89a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c48d5433-9a94-4fe3-bd99-894974cfd145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(validset[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfe2d1-b69e-4875-bb63-536c1e1dfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "44c7fd77-4999-4ec6-823f-3c3bacf58168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall(\n",
    "    '(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "    ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2aed49e2-b86f-4a1a-9d04-c9c78fc7e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter()\n",
    "for line in trainset:\n",
    "    tokens = tokenizer(line['text'])\n",
    "    token_counts.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4bb417e-c203-4c31-9b94-0a4183fc0ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f639bd3b-06de-4f47-be43-c168bf1bd797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 68745\n"
     ]
    }
   ],
   "source": [
    "print('Vocab-size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b13ce637-eb95-4daf-855a-f2c492981dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.vocab \n",
    "\n",
    "sorted_by_freq_tuples = sorted(\n",
    "    token_counts.items(), key=lambda x: x[1], reverse = True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "bb1c5234-8289-45c3-89b5-b7ecbce76381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68745\n"
     ]
    }
   ],
   "source": [
    "print(len(ordered_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a435890d-c3fc-4125-ba1b-bc6ae50c3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68745lines [00:00, 198338.81lines/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[43mvocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_by_freq_tuples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torchtext/vocab.py:560\u001b[0m, in \u001b[0;36mbuild_vocab_from_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    558\u001b[0m         counter\u001b[38;5;241m.\u001b[39mupdate(tokens)\n\u001b[1;32m    559\u001b[0m         t\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 560\u001b[0m word_vocab \u001b[38;5;241m=\u001b[39m \u001b[43mVocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m word_vocab\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torchtext/vocab.py:77\u001b[0m, in \u001b[0;36mVocab.__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m counter[tok]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# sort by frequency, then alphabetically\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m words_and_frequencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcounter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtup\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m words_and_frequencies\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m tup: tup[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, freq \u001b[38;5;129;01min\u001b[39;00m words_and_frequencies:\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "vocab = vocab(sorted_by_freq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "183a9f5d-4672-49a4-91de-1066bb7a3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator as vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4344e6a1-ad29-481e-9c58-bbea9082afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e6294fef-59ce-486f-836f-b7d421fedbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(vocab['and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "054e4718-7d91-4d0c-8498-78ccb78db414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266596\n"
     ]
    }
   ],
   "source": [
    "print(ordered_dict.get('the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d9696109-312e-4dda-8d54-68a9083353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ca469c1a-f784-4c45-b86f-812a99410df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "db0bd8bc-ad7f-47cc-acbc-6ac190aa30ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39b74a3c6d64282a42017bb95d12980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c990553b168d424b8d521941907d4e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d0702b3320462cb8aaffcff6cbc08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cac29bfc76447dbc14781825e6efdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "32094d95-082b-4fc0-b19b-0386ecd95899",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2530\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2529\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2530\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2588\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2588\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2589\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2590\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2591\u001b[0m     )\n\u001b[1;32m   2593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2595\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2596\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2597\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(train_dataset[0], padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "72bfc0f9-3f6d-44d7-9c17-aca74250c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b0bc8891-7a7a-4b7e-ad3b-f20c59ed12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "30af16c6-5cfb-42ce-8de7-21ba390eee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/abhijit/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-02cdd5a9126ebef7.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = train_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "0cbedfcf-e0a8-45b2-885e-81a465a1fb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "5a3464b6-0e20-408b-b6ad-651a87a5b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4e27bc0e-618c-46fe-96d4-786cffcf7ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c5ed7ff8-5257-4830-aa5d-8d0d9891aece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print((tokenized_datasets[:1]['label'][0].float()).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "989f4756-fe66-4623-a140-4c23f35bafa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dataset' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[361], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Dataset' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "tokenized_datasets['label'] = tokenized_datasets['label'].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ed28cd19-d72e-4eff-9f1f-6f8d5693733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "34a58450-ab81-4149-99e2-15c9cc980a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dl = DataLoader(tokenized_datasets, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dd3a6260-7358-4ea4-a6f2-9f612c58c3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text label\n"
     ]
    }
   ],
   "source": [
    "X, y, l, k, z = next(iter(train_dl))\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "987979a2-61aa-4dd5-84b8-b9e0fcb20bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset[:2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "413c7fa5-b0bb-44ab-b04e-cc1af1c4e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.6755, -1.6676,  1.2994],\n",
      "         [ 2.0843,  0.2214, -0.2201],\n",
      "         [ 0.2629, -0.7579, -0.6529],\n",
      "         [ 0.3606, -1.2950, -0.0311]],\n",
      "\n",
      "        [[ 0.2629, -0.7579, -0.6529],\n",
      "         [ 1.3744, -2.3288, -1.4609],\n",
      "         [ 2.0843,  0.2214, -0.2201],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(\n",
    "    num_embeddings = 10,\n",
    "    embedding_dim = 3,\n",
    "    padding_idx = 0)\n",
    "text_encoded_input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 0]])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "558de184-9e54-41ba-a0e5-2f68157aaf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnn(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "torch.Size([5, 32]) tensor([[-0.2105,  0.4410, -0.6201,  0.2708, -0.2334, -0.5282,  0.2158, -0.0867,\n",
      "         -0.0335, -0.3827,  0.1983, -0.1298,  0.2245,  0.7044, -0.8089, -0.1554,\n",
      "          0.4825, -0.0040, -0.2078, -0.0589, -0.5860,  0.6425,  0.7338,  0.1732,\n",
      "          0.4231, -0.0920, -0.4155, -0.5559, -0.3367, -0.3995,  0.6020,  0.4761],\n",
      "        [ 0.1690, -0.1267,  0.3722, -0.7329,  0.1795,  0.1470, -0.5854,  0.2531,\n",
      "          0.0532, -0.0901,  0.0494,  0.2562, -0.2022,  0.3411,  0.2734, -0.0135,\n",
      "          0.4384,  0.2889, -0.0985,  0.1023, -0.4628,  0.2223,  0.4363,  0.3439,\n",
      "          0.2239,  0.2290,  0.1681, -0.3073, -0.5171, -0.0864,  0.2057,  0.5356],\n",
      "        [ 0.5015,  0.3651, -0.5262,  0.0329, -0.2693, -0.1585, -0.0616,  0.0425,\n",
      "         -0.3679,  0.6931, -0.2032, -0.1007,  0.5572,  0.8043, -0.3500, -0.2360,\n",
      "          0.7649,  0.5358, -0.6805, -0.3419,  0.3178,  0.0825, -0.2369, -0.0843,\n",
      "         -0.4262, -0.1082,  0.0140, -0.1453,  0.0955,  0.3270,  0.0063, -0.1908],\n",
      "        [ 0.2977, -0.0690, -0.2429, -0.0794, -0.0250, -0.1374, -0.2275,  0.1422,\n",
      "          0.1271,  0.4044, -0.1664, -0.1211,  0.0754,  0.3601,  0.5433,  0.1962,\n",
      "         -0.2022, -0.3087, -0.3373, -0.2200,  0.2208,  0.1311,  0.0616, -0.1194,\n",
      "          0.2654,  0.0883,  0.3572, -0.1821,  0.0769, -0.2327, -0.0309,  0.0527],\n",
      "        [-0.0507,  0.3915, -0.7226, -0.4247, -0.3000,  0.3074,  0.0136, -0.1717,\n",
      "          0.5153,  0.0931,  0.2568, -0.5103,  0.1409,  0.4338, -0.5955, -0.3762,\n",
      "          0.2304,  0.4384, -0.8012,  0.5297, -0.1534,  0.0604,  0.4351, -0.0833,\n",
      "          0.5838, -0.0701, -0.4394, -0.4942,  0.3475, -0.3854,  0.1602,  0.1807]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4998],\n",
       "        [-0.0959],\n",
       "        [-0.1825],\n",
       "        [-0.1297],\n",
       "        [-0.0831]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "        #self.rnn = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = hidden[-1, :, :]\n",
    "        print(out.shape, out)\n",
    "        x = self.fc(out)\n",
    "        return x\n",
    "\n",
    "model = Rnn(64, 32)\n",
    "print(model)\n",
    "model(torch.randn(5, 3, 64))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "0f6c4d28-76dc-4579-8cda-2d498e443ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim , padding_idx = 0)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first = True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, text):\n",
    "        out = self.embedding(text)\n",
    "        #out = nn.utils.rnn.pack_padded_sequence( \n",
    "        #    out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out =  hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "690c2955-6ee4-4f96-b1ba-78b7feba8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnn(\n",
      "  (embedding): Embedding(68745, 20, padding_idx=0)\n",
      "  (rnn): LSTM(20, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(ordered_dict)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "model = Rnn(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "cb66f88d-0c7a-4719-a52f-da5ac41b85a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "aaad744c-5098-4a6e-bea6-5d4f4595aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for l in dataloader:\n",
    "        pred = model(l['input_ids'])[:,0]\n",
    "        loss = loss_fn(pred, l['label'].float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #total_acc += ((pred >= 0.5).float() == label_batch).sum().item()\n",
    "        total_acc = 0\n",
    "        total_loss += loss.item()*l['label'].size(0)\n",
    "        \n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "22307b6a-59f5-429f-b9e4-5084f4c08f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "95e0faed-76ff-4322-8a8c-b98e918cee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.6911\n",
      "Epoch 1 loss: 0.6854\n",
      "Epoch 2 loss: 0.6842\n",
      "Epoch 3 loss: 0.6821\n",
      "Epoch 4 loss: 0.6696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[381], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 3\u001b[0m     acc_train, loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[375], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 9\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#total_acc += ((pred >= 0.5).float() == label_batch).sum().item()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m total_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    print(f'Epoch {epoch} loss: {loss_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f1eea787-1671-4502-8082-6f1dddc22468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 146,\n",
       " 12765,\n",
       " 146,\n",
       " 6586,\n",
       " 140,\n",
       " 19556,\n",
       " 19368,\n",
       " 13329,\n",
       " 118,\n",
       " 162,\n",
       " 21678,\n",
       " 2162,\n",
       " 17056,\n",
       " 1121,\n",
       " 1139,\n",
       " 1888,\n",
       " 2984,\n",
       " 1272,\n",
       " 1104,\n",
       " 1155,\n",
       " 1103,\n",
       " 6392,\n",
       " 1115,\n",
       " 4405,\n",
       " 1122,\n",
       " 1165,\n",
       " 1122,\n",
       " 1108,\n",
       " 1148,\n",
       " 1308,\n",
       " 1107,\n",
       " 2573,\n",
       " 119,\n",
       " 146,\n",
       " 1145,\n",
       " 1767,\n",
       " 1115,\n",
       " 1120,\n",
       " 1148,\n",
       " 1122,\n",
       " 1108,\n",
       " 7842,\n",
       " 1118,\n",
       " 158,\n",
       " 119,\n",
       " 156,\n",
       " 119,\n",
       " 10148,\n",
       " 1191,\n",
       " 1122,\n",
       " 1518,\n",
       " 1793,\n",
       " 1106,\n",
       " 3873,\n",
       " 1142,\n",
       " 1583,\n",
       " 117,\n",
       " 3335,\n",
       " 1217,\n",
       " 170,\n",
       " 5442,\n",
       " 1104,\n",
       " 2441,\n",
       " 1737,\n",
       " 107,\n",
       " 6241,\n",
       " 107,\n",
       " 146,\n",
       " 1541,\n",
       " 1125,\n",
       " 1106,\n",
       " 1267,\n",
       " 1142,\n",
       " 1111,\n",
       " 1991,\n",
       " 119,\n",
       " 133,\n",
       " 9304,\n",
       " 120,\n",
       " 135,\n",
       " 133,\n",
       " 9304,\n",
       " 120,\n",
       " 135,\n",
       " 1109,\n",
       " 4928,\n",
       " 1110,\n",
       " 8663,\n",
       " 1213,\n",
       " 170,\n",
       " 1685,\n",
       " 3619,\n",
       " 3362,\n",
       " 2377,\n",
       " 1417,\n",
       " 14960,\n",
       " 1150,\n",
       " 3349,\n",
       " 1106,\n",
       " 3858,\n",
       " 1917,\n",
       " 1131,\n",
       " 1169,\n",
       " 1164,\n",
       " 1297,\n",
       " 119,\n",
       " 1130,\n",
       " 2440,\n",
       " 1131,\n",
       " 3349,\n",
       " 1106,\n",
       " 2817,\n",
       " 1123,\n",
       " 2209,\n",
       " 1116,\n",
       " 1106,\n",
       " 1543,\n",
       " 1199,\n",
       " 3271,\n",
       " 1104,\n",
       " 4148,\n",
       " 1113,\n",
       " 1184,\n",
       " 1103,\n",
       " 1903,\n",
       " 156,\n",
       " 11547,\n",
       " 1162,\n",
       " 1354,\n",
       " 1164,\n",
       " 2218,\n",
       " 1741,\n",
       " 2492,\n",
       " 1216,\n",
       " 1112,\n",
       " 1103,\n",
       " 4357,\n",
       " 1414,\n",
       " 1105,\n",
       " 1886,\n",
       " 2492,\n",
       " 1107,\n",
       " 1103,\n",
       " 1244,\n",
       " 1311,\n",
       " 119,\n",
       " 1130,\n",
       " 1206,\n",
       " 4107,\n",
       " 8673,\n",
       " 1105,\n",
       " 6655,\n",
       " 10552,\n",
       " 3708,\n",
       " 2316,\n",
       " 1104,\n",
       " 8583,\n",
       " 1164,\n",
       " 1147,\n",
       " 11089,\n",
       " 1113,\n",
       " 4039,\n",
       " 117,\n",
       " 1131,\n",
       " 1144,\n",
       " 2673,\n",
       " 1114,\n",
       " 1123,\n",
       " 3362,\n",
       " 3218,\n",
       " 117,\n",
       " 22150,\n",
       " 117,\n",
       " 1105,\n",
       " 1597,\n",
       " 1441,\n",
       " 119,\n",
       " 133,\n",
       " 9304,\n",
       " 120,\n",
       " 135,\n",
       " 133,\n",
       " 9304,\n",
       " 120,\n",
       " 135,\n",
       " 1327,\n",
       " 8567,\n",
       " 1143,\n",
       " 1164,\n",
       " 146,\n",
       " 6586,\n",
       " 140,\n",
       " 19556,\n",
       " 19368,\n",
       " 13329,\n",
       " 118,\n",
       " 162,\n",
       " 21678,\n",
       " 2162,\n",
       " 17056,\n",
       " 1110,\n",
       " 1115,\n",
       " 1969,\n",
       " 1201,\n",
       " 2403,\n",
       " 117,\n",
       " 1142,\n",
       " 1108,\n",
       " 1737,\n",
       " 185,\n",
       " 8456,\n",
       " 9597,\n",
       " 119,\n",
       " 8762,\n",
       " 117,\n",
       " 1103,\n",
       " 2673,\n",
       " 1105,\n",
       " 183,\n",
       " 17294,\n",
       " 2340,\n",
       " 4429,\n",
       " 1132,\n",
       " 1374,\n",
       " 1105,\n",
       " 1677,\n",
       " 1206,\n",
       " 117,\n",
       " 1256,\n",
       " 1173,\n",
       " 1122,\n",
       " 112,\n",
       " 188,\n",
       " 1136,\n",
       " 2046,\n",
       " 1176,\n",
       " 1199,\n",
       " 10928,\n",
       " 1193,\n",
       " 1189,\n",
       " 185,\n",
       " 8456,\n",
       " 1186,\n",
       " 119,\n",
       " 1799,\n",
       " 1139,\n",
       " 1583,\n",
       " 2354,\n",
       " 1713,\n",
       " 1525,\n",
       " 1122,\n",
       " 19196,\n",
       " 117,\n",
       " 1107,\n",
       " 3958,\n",
       " 2673,\n",
       " 1105,\n",
       " 183,\n",
       " 17294,\n",
       " 2340,\n",
       " 1132,\n",
       " 170,\n",
       " 1558,\n",
       " 22088,\n",
       " 1107,\n",
       " 3619,\n",
       " 7678,\n",
       " 119,\n",
       " 2431,\n",
       " 1130,\n",
       " 14721,\n",
       " 1197,\n",
       " 27644,\n",
       " 117,\n",
       " 18271,\n",
       " 1147,\n",
       " 2590,\n",
       " 1106,\n",
       " 1363,\n",
       " 1385,\n",
       " 2298,\n",
       " 1287,\n",
       " 4100,\n",
       " 117,\n",
       " 1125,\n",
       " 2673,\n",
       " 4429,\n",
       " 1107,\n",
       " 1117,\n",
       " 2441,\n",
       " 119,\n",
       " 133,\n",
       " 9304,\n",
       " 120,\n",
       " 135,\n",
       " 133,\n",
       " 9304,\n",
       " 120,\n",
       " 135,\n",
       " 146,\n",
       " 1202,\n",
       " 3254,\n",
       " 2354,\n",
       " 1181,\n",
       " 1103,\n",
       " 18992,\n",
       " 1111,\n",
       " 1103,\n",
       " 1864,\n",
       " 1115,\n",
       " 1251,\n",
       " 2673,\n",
       " 2602,\n",
       " 1107,\n",
       " 1103,\n",
       " 1273,\n",
       " 1110,\n",
       " 2602,\n",
       " 1111,\n",
       " 6037,\n",
       " 4998,\n",
       " 1897,\n",
       " 1190,\n",
       " 1198,\n",
       " 1106,\n",
       " 4900,\n",
       " 1234,\n",
       " 1105,\n",
       " 1294,\n",
       " 1948,\n",
       " 1106,\n",
       " 1129,\n",
       " 2602,\n",
       " 1107,\n",
       " 185,\n",
       " 8456,\n",
       " 9597,\n",
       " 13090,\n",
       " 1107,\n",
       " 1738,\n",
       " 119,\n",
       " 146,\n",
       " 6586,\n",
       " 140,\n",
       " 19556,\n",
       " 19368,\n",
       " 13329,\n",
       " 118,\n",
       " 162,\n",
       " 21678,\n",
       " 2162,\n",
       " 17056,\n",
       " 1110,\n",
       " 170,\n",
       " 1363,\n",
       " 1273,\n",
       " 1111,\n",
       " 2256,\n",
       " 5277,\n",
       " 1106,\n",
       " 2025,\n",
       " 1103,\n",
       " 6092,\n",
       " 1105,\n",
       " 15866,\n",
       " 113,\n",
       " 1185,\n",
       " 23609,\n",
       " 1179,\n",
       " 3005,\n",
       " 114,\n",
       " 1104,\n",
       " 3619,\n",
       " 7678,\n",
       " 119,\n",
       " 1252,\n",
       " 1541,\n",
       " 117,\n",
       " 1142,\n",
       " 1273,\n",
       " 2144,\n",
       " 112,\n",
       " 189,\n",
       " 1138,\n",
       " 1277,\n",
       " 1104,\n",
       " 170,\n",
       " 4928,\n",
       " 119,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e0d088c4-0311-4859-84d3-f6a324af50d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1252,  1184,  1164,  1248,  6462,   136,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1790,   112,   189,  1341,  1119,  3520,  1164,  1248,  6462,\n",
      "           117, 21902,  1643,   119,   102],\n",
      "        [  101,  1327,  1164,  5450, 23434,   136,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e085220a-4018-493c-af9e-d17bfbee4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517df4c3-a8cf-4e84-9ca8-b2a002c489e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
